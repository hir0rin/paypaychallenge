# Requirements
```
このシステムの要件:

大量の書き込み処理: 1日あたり10億件の書き込みイベント

大量の読み込み/問い合わせ処理: 100万のユーザーがビジネス分析を要望 読み込み/問い合わせのパターンはメトリクスの時系列となる

最大1時間の遅延でメトリクスを提供

最小のダウンタイムで実行

処理ロジックにバグがある場合、履歴データの再処理が可能
```

# Architecture
## Backend
### Fact Data(Base Data)
特に大量の書き込みが発生するため、高スループットにピンを留めてKey-Value Store型DBであるAmazon DynamoDBを採用します。

### Metrics Data(Processed Data)
ファクトデータの書き込みイベントに対応してメッセージキューにコンシューマを登録し、非同期でメトリクスデータの生成・永続化を行います。
メッセージキューの処理にはApache Kafkaを用います。

メトリクスデータの永続化方法は具体的な使用用途に依存しますが、ファクトデータからは直接の依存を切り離しているため、個々の目的に応じて選択することが可能です。
各メトリクスの結合を伴うような複雑なものはAmazon AuroraといったマネージドRDB、テキストや数値・区分等の全文検索にはAmazon Elasticsearch Serviceを用います。

ファクトデータとメトリクスデータ間の整合性を担保しつつ開発効率を上げるため、ファクトデータの読み書きを行う際のIntercepterをフレームワークとして用意します。
また、バッチ処理での再生成ロジックも用意することで、全ファクトデータを使ったメトリクスデータの再生成も任意のタイミングで行うことが可能です。

## AP
マイクロサービスアーキテクチャを採用し、各サービス間での連携はWebAPIを介して行うことで、
サービス間での密な依存を避け、各サービスごとの開発・運用効率を高めます。

また、各サービスはDockerとしてコンテナ化を行い、これらの運用にkubernetesを用います。
システム全体のスケーラビリティを担保しつつ、ローリングアップデートによる最小のダウンタイムでのバージョン更新も実現します。
